{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51O7My35KxhM"
   },
   "source": [
    "# Model Building Phase 2: Enhanced MentalBERT Classifier\n",
    "\n",
    "This notebook refines data and training procedures to improve real-world accuracy of the `mental/mental-bert-base-uncased` classifier. All code is organized into clear sections for execution on Google Colab with GPU support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8rhWkClK80J"
   },
   "source": [
    "## 1. Environment & Dependency Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "14CBWpflDiHS",
    "outputId": "dc92a73e-8ee2-4678-9fd5-415e8baa8d05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.8.0+cu126\n",
      "Uninstalling torch-2.8.0+cu126:\n",
      "  Successfully uninstalled torch-2.8.0+cu126\n",
      "Found existing installation: torchvision 0.23.0+cu126\n",
      "Uninstalling torchvision-0.23.0+cu126:\n",
      "  Successfully uninstalled torchvision-0.23.0+cu126\n",
      "Found existing installation: torchaudio 2.8.0+cu126\n",
      "Uninstalling torchaudio-2.8.0+cu126:\n",
      "  Successfully uninstalled torchaudio-2.8.0+cu126\n",
      "Found existing installation: transformers 4.57.1\n",
      "Uninstalling transformers-4.57.1:\n",
      "  Successfully uninstalled transformers-4.57.1\n",
      "Found existing installation: huggingface-hub 0.35.3\n",
      "Uninstalling huggingface-hub-0.35.3:\n",
      "  Successfully uninstalled huggingface-hub-0.35.3\n",
      "Found existing installation: diffusers 0.35.2\n",
      "Uninstalling diffusers-0.35.2:\n",
      "  Successfully uninstalled diffusers-0.35.2\n",
      "Found existing installation: gradio 5.49.1\n",
      "Uninstalling gradio-5.49.1:\n",
      "  Successfully uninstalled gradio-5.49.1\n",
      "Found existing installation: pyarrow 18.1.0\n",
      "Uninstalling pyarrow-18.1.0:\n",
      "  Successfully uninstalled pyarrow-18.1.0\n",
      "Found existing installation: fsspec 2025.3.0\n",
      "Uninstalling fsspec-2025.3.0:\n",
      "  Successfully uninstalled fsspec-2025.3.0\n",
      "Found existing installation: websockets 15.0.1\n",
      "Uninstalling websockets-15.0.1:\n",
      "  Successfully uninstalled websockets-15.0.1\n",
      "Found existing installation: numpy 2.0.2\n",
      "Uninstalling numpy-2.0.2:\n",
      "  Successfully uninstalled numpy-2.0.2\n",
      "Found existing installation: pandas 2.2.2\n",
      "Uninstalling pandas-2.2.2:\n",
      "  Successfully uninstalled pandas-2.2.2\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.8.4 requires pandas, which is not installed.\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, which is not installed.\n",
      "fastai 2.8.4 requires torchvision>=0.11, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pip-25.2\n",
      "Collecting numpy==1.26.4\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting pandas==2.2.3\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting pyarrow==14.0.1\n",
      "  Downloading pyarrow-14.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting fsspec==2025.3.0\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas==2.2.3) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.3) (1.17.0)\n",
      "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-14.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (38.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Installing collected packages: numpy, fsspec, pyarrow, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, which is not installed.\n",
      "fastai 2.8.4 requires torchvision>=0.11, which is not installed.\n",
      "accelerate 1.10.1 requires huggingface_hub>=0.21.0, which is not installed.\n",
      "accelerate 1.10.1 requires torch>=2.0.0, which is not installed.\n",
      "yfinance 0.2.66 requires websockets>=13.0, which is not installed.\n",
      "datasets 4.0.0 requires huggingface-hub>=0.24.0, which is not installed.\n",
      "sentence-transformers 5.1.1 requires huggingface-hub>=0.20.0, which is not installed.\n",
      "sentence-transformers 5.1.1 requires torch>=1.11.0, which is not installed.\n",
      "sentence-transformers 5.1.1 requires transformers<5.0.0,>=4.41.0, which is not installed.\n",
      "torchtune 0.6.1 requires huggingface_hub[hf_transfer], which is not installed.\n",
      "peft 0.17.1 requires huggingface_hub>=0.25.0, which is not installed.\n",
      "peft 0.17.1 requires torch>=1.13.0, which is not installed.\n",
      "peft 0.17.1 requires transformers, which is not installed.\n",
      "gradio-client 1.13.3 requires huggingface-hub<2.0,>=0.19.3, which is not installed.\n",
      "gradio-client 1.13.3 requires websockets<16.0,>=13.0, which is not installed.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 2.24.0 requires pyarrow>=15.0.2, but you have pyarrow 14.0.1 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "datasets 4.0.0 requires pyarrow>=15.0.0, but you have pyarrow 14.0.1 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2025.3.0 numpy-1.26.4 pandas-2.2.3 pyarrow-14.0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "87e020e53e284cf1b87178c23d2fd20c",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.4.1 (from versions: 2.6.0+cu126, 2.7.0+cu126, 2.7.1+cu126, 2.8.0+cu126, 2.9.0+cu126)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.4.1\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting transformers==4.45.1\n",
      "  Downloading transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting huggingface-hub==0.26.2\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting datasets==3.0.2\n",
      "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting accelerate==1.1.1\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.1) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.1) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.1) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.1) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.1) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.1) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.1) (0.6.2)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers==4.45.1)\n",
      "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.45.1) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.26.2) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub==0.26.2) (4.15.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets==3.0.2)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.2) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.2) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.2) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.2) (0.70.16)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub==0.26.2)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==3.0.2) (3.13.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==1.1.1) (5.9.5)\n",
      "Collecting torch>=1.10.0 (from accelerate==1.1.1)\n",
      "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.2) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.2) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.2) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.2) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.2) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.2) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==3.0.2) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==3.0.2) (3.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.1) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.45.1) (2025.10.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==1.1.1) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==1.1.1) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==1.1.1) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==1.1.1) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==1.1.1) (9.10.2.21)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10.0->accelerate==1.1.1) (0.7.1)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.5.0 (from torch>=1.10.0->accelerate==1.1.1)\n",
      "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10.0->accelerate==1.1.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10.0->accelerate==1.1.1) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.0.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.0.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets==3.0.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.0.2) (1.17.0)\n",
      "Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m130.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
      "Downloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (899.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m  \u001b[33m0:00:22\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m  \u001b[33m0:00:13\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, pyarrow, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, datasets, accelerate\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.4.0\n",
      "\u001b[2K    Uninstalling triton-3.4.0:\n",
      "\u001b[2K      Successfully uninstalled triton-3.4.0\n",
      "\u001b[2K  Attempting uninstall: pyarrow\n",
      "\u001b[2K    Found existing installation: pyarrow 14.0.1\n",
      "\u001b[2K    Uninstalling pyarrow-14.0.1:\n",
      "\u001b[2K      Successfully uninstalled pyarrow-14.0.1\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufile-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
      "\u001b[2K    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "\u001b[2K  Attempting uninstall: fsspec\n",
      "\u001b[2K    Found existing installation: fsspec 2025.3.0\n",
      "\u001b[2K    Uninstalling fsspec-2025.3.0:\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.3.0\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "\u001b[2K  Attempting uninstall: tokenizers\n",
      "\u001b[2K    Found existing installation: tokenizers 0.22.1\n",
      "\u001b[2K    Uninstalling tokenizers-0.22.1:\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.22.1\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "\u001b[2K  Attempting uninstall: datasets\n",
      "\u001b[2K    Found existing installation: datasets 4.0.0\n",
      "\u001b[2K    Uninstalling datasets-4.0.0:\n",
      "\u001b[2K      Successfully uninstalled datasets-4.0.0\n",
      "\u001b[2K  Attempting uninstall: accelerate\n",
      "\u001b[2K    Found existing installation: accelerate 1.10.1\n",
      "\u001b[2K    Uninstalling accelerate-1.10.1:\n",
      "\u001b[2K      Successfully uninstalled accelerate-1.10.1\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/22\u001b[0m [accelerate]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.8.4 requires torchvision>=0.11, which is not installed.\n",
      "timm 1.0.20 requires torchvision, which is not installed.\n",
      "gradio-client 1.13.3 requires websockets<16.0,>=13.0, which is not installed.\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0 which is incompatible.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.1.1 datasets-3.0.2 fsspec-2024.9.0 huggingface-hub-0.26.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pyarrow-21.0.0 tokenizers-0.20.3 torch-2.9.0 transformers-4.45.1 triton-3.5.0\n",
      "Collecting websockets==13.0\n",
      "  Downloading websockets-13.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
      "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.45.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.19.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.5)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Collecting numpy>=1.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.23.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading websockets-13.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m140.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: websockets, numpy, emoji\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [emoji]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.8.4 requires torchvision>=0.11, which is not installed.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "fastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
      "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "dataproc-spark-connect 0.8.3 requires websockets>=14.0, but you have websockets 13.0 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
      "google-adk 1.16.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 13.0 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed emoji-2.15.0 numpy-2.3.4 websockets-13.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "a6d3dba4bd5f4e16b32cd097139dff19",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "All libraries installed successfully!\n",
      "Torch: 2.9.0+cu128\n",
      "CUDA available: True\n",
      "GPU device: Tesla T4\n",
      "Transformers: 4.45.1\n",
      "Datasets: 3.0.2\n",
      "SpaCy: 3.8.7\n",
      "NumPy: 2.0.2\n",
      "Pandas: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio transformers huggingface_hub diffusers gradio pyarrow fsspec websockets numpy pandas\n",
    "!pip install --upgrade pip\n",
    "!pip install numpy==1.26.4 pandas==2.2.3 pyarrow==14.0.1 fsspec==2025.3.0\n",
    "!pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu126\n",
    "!pip install transformers==4.45.1 huggingface-hub==0.26.2 datasets==3.0.2 accelerate==1.1.1\n",
    "!pip install websockets==13.0 emoji textblob sentence-transformers spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "import torch, transformers, datasets, spacy, numpy, pandas\n",
    "print(\"All libraries installed successfully!\")\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU device:\", torch.cuda.get_device_name(0))\n",
    "print(\"Transformers:\", transformers.__version__)\n",
    "print(\"Datasets:\", datasets.__version__)\n",
    "print(\"SpaCy:\", spacy.__version__)\n",
    "print(\"NumPy:\", numpy.__version__)\n",
    "print(\"Pandas:\", pandas.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141,
     "referenced_widgets": [
      "5421c8452c0042e8a718050c8d7362a5",
      "5721c381a41b4fbc8b1cb816dde0cbb7",
      "cd19e9d802614b3d9d23e2bc940a0705",
      "944e3ab13a774ff58c2cba21b03b7103",
      "e182904e7ea74ac0b521a5b7dcb702c8",
      "ea0b438c70584806af8ed81f595bf778",
      "11de419aeae8463d8484ec9a676fbb8c",
      "f78c09cd92cd47a4a1029b2d8425580c",
      "8786346511794b3b93d012447f2a04c8",
      "155cf34d4a974874878e5bdab811f50a",
      "de5d5ab3883d4d2b837d90a0da0a0b80",
      "4e642c21a86d4936ae8c89d80a3fa9bc",
      "56e97c524636494a8e501c09f1ec2304",
      "1abf557e030c401e9ebc1a08b0699f6d",
      "c43270bf48074c369092377a5bfb12b1",
      "8759822d70984e7e9595ff96b83f5e82",
      "bf001fd6e3b84e5aaf455ec527cd63d9",
      "97b4c694df5f4ca7911fdc706c964756",
      "c67d18d42060428b897aad597a404c6e",
      "91d8682e9b2c43a1bc0e41d456470185"
     ]
    },
    "id": "VCRrUjdeLQDR",
    "outputId": "af147c3d-4734-439b-fff9-201324de35a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(new_session=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7x31rGqK_4k"
   },
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KiPXZbhoLC05",
    "outputId": "adaf5fe0-b05e-4945-96d4-1f8c378abea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL BUILDING PHASE 2 STARTED\n",
      "Torch version: 2.9.0+cu128\n",
      "CUDA available: True\n",
      "GPU device in use: Tesla T4\n",
      "Using device: cuda\n",
      "Initialization and imports completed in 0.01 seconds.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# Start timing the initialization\n",
    "init_start = time.time()\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, recall_score, precision_score\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"MODEL BUILDING PHASE 2 STARTED\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device in use: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# End timing and print duration\n",
    "init_end = time.time()\n",
    "print(f\"Initialization and imports completed in {init_end - init_start:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hG7cIMpBLIX4"
   },
   "source": [
    "## 2. Upload and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "JOu5yJcQLWPb",
    "outputId": "f4c78b7f-d2f6-47b5-9d72-7c4f27a3cb22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload: features_interpretable.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-42ea68be-e232-4090-a351-72bac0f4a953\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-42ea68be-e232-4090-a351-72bac0f4a953\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features_interpretable.csv to features_interpretable.csv\n",
      "Filtered classes: ['Anxiety' 'Normal' 'Depression' 'Suicidal']\n",
      "Total samples: 40012\n"
     ]
    }
   ],
   "source": [
    "print(\"Upload: features_interpretable.csv\")\n",
    "uploaded = files.upload()\n",
    "assert 'features_interpretable.csv' in uploaded\n",
    "\n",
    "df = pd.read_csv('features_interpretable.csv')\n",
    "df = df[df['status'].isin(['Anxiety','Depression','Normal','Suicidal'])]\n",
    "print(\"Filtered classes:\", df['status'].unique())\n",
    "print(\"Total samples:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwTID944Lfgo"
   },
   "source": [
    "## 3. Preprocessing & Augmentation\n",
    "Cleans whitespace and basic text noise, then balances the dataset by duplicating minority-class samples until each class has equal support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKJqb15ELhmr",
    "outputId": "5a657184-93dc-4dd3-a01f-f239b5196074"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code start: Basic cleanup and augmentation...\n",
      "Post-augmentation distribution:\n",
      " status\n",
      "Normal        15991\n",
      "Anxiety       15515\n",
      "Depression    12106\n",
      "Suicidal       8812\n",
      "Name: count, dtype: int64\n",
      "Code finished in 1.56 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Code start: Basic cleanup and augmentation...\")\n",
    "\n",
    "# Basic cleanup\n",
    "df['statement'] = df['statement'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "\n",
    "# Augmentation: duplicate minority classes until balanced\n",
    "counts = df['status'].value_counts()\n",
    "max_count = counts.max()\n",
    "augmented = []\n",
    "\n",
    "for label, cnt in counts.items():\n",
    "    samples = df[df['status'] == label]\n",
    "    if cnt < max_count:\n",
    "        reps = max_count // cnt - 1\n",
    "        if reps > 0:  # Only augment if reps > 0\n",
    "            augmented.append(pd.concat([samples]*reps, ignore_index=True))\n",
    "\n",
    "if augmented:\n",
    "    df = pd.concat([df] + augmented, ignore_index=True)\n",
    "\n",
    "print(\"Post-augmentation distribution:\\n\", df['status'].value_counts())\n",
    "print(f\"Code finished in {time.time() - start_time:.2f} seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bt-lGLfGOcUz"
   },
   "source": [
    "*Decision Note: Simple cleaning eliminates obvious formatting artifacts without overprocessing. Basic duplication provides immediate class balance; more advanced augmentation (e.g., synonym replacement) can be added as needed but was deferred to maintain reproducibility and minimize introduction of spurious patterns.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tH6jZ0f7Lv2c"
   },
   "source": [
    "## 4. Label Encoding and Split\n",
    "Maps string labels to integer IDs and performs an 80/20 stratified train/validation split, preserving class proportions across sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5povd_cL-Sx",
    "outputId": "1cf75935-ea65-4e7c-83ed-328d60095132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code start: Label mapping and train/validation split...\n",
      "Train/Validation sizes: 41939 / 10485\n",
      "Code finished in 0.04 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Code start: Label mapping and train/validation split...\")\n",
    "\n",
    "# Define label mappings\n",
    "label2id = {'Anxiety': 0, 'Depression': 1, 'Normal': 2, 'Suicidal': 3}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Map labels in the dataframe\n",
    "df['label'] = df['status'].map(label2id)\n",
    "assert not df['label'].isnull().any(), \"Some labels could not be mapped!\"\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train/Validation sizes: {len(train_df)} / {len(val_df)}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Code finished in\", round(end_time - start_time, 2), \"seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mpEe-y9L9tg"
   },
   "source": [
    "## 5. Dataset & DataLoader\n",
    "Defines a custom PyTorch Dataset class to tokenize and encode text samples on-the-fly, paired with their integer labels. DataLoader batches and shuffles training data for efficient GPU processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252,
     "referenced_widgets": [
      "87acda72b00245a189745c8a55862292",
      "255cc6c8bf274f94803ae275d0689381",
      "55f9bde38c594f84829388c518f2f5ff",
      "17353650086b45fcb8b46b4d886cb200",
      "f89e96b694034ad9a3c4702b634f841a",
      "01227ca5acf245249cf22ced3d7e66f6",
      "f74623ce3ced4d9dabca728f306e299b",
      "10d0beee3d084cedb4e6e706d769a455",
      "98f8f64e43624411abd376900e6c3cbf",
      "c4e7896e68114ba6a73dbfcda932289d",
      "86fccc7085be43758ef3a7848a425b04",
      "ef76a21040e2402383b8ba130bbfc973",
      "4d56f8c4c9fd4fc78dd55971ae84706e",
      "88b30e96e105425cac26d491050f42c3",
      "7a2ca186ef6847af88a4d8b1cd3e66f8",
      "fea7c08397bb49ecb01f2ea1ce5e2fab",
      "500f79aefe404dbbb1c803e4714633ee",
      "480b583902f2430d8dd9f6b0ecfa22b8",
      "247beff19d164c21bcdfe625bab49c4f",
      "a94bf0e4184f48fdbb1df88aa6f52f5e",
      "b6e1d65f739d4965b31c9d80393c46fa",
      "f6c3c5f8062746578bf01ee91129177d",
      "ce342f32f5fe4c6d93581a0983aef038",
      "81202c0e3ec54ad89a608f4db966529a",
      "e92b7be31d484da5843bd337d03823ed",
      "e40891ce06104b5c88fb8513b7bfd1d9",
      "46880316583842bdbaa0d1beea60ef3b",
      "0b9dc73fd07c4c52915f3eab25f28f99",
      "11e7c1f6b29e442aaedbfc6a5a8822f4",
      "d7bd0180e01b42edb2997be109df97e8",
      "f00205c51a764800a04f46edc1a6a3ea",
      "c1eb537c2fe94e1f98ecb2eb0f7fb46b",
      "adbc2f06874f4be6822f7aaa8ea992db",
      "ea08ceacfbf841c2b09973b1d220eee0",
      "58ba9d1c20d04e748e90793d17cde322",
      "355b04a1bf7b43a2a303aceaf5e94695",
      "3414672fb0aa46478e274705e7aece7a",
      "0a8e8f303bcb44b6ac07aa3de08e460d",
      "08f66ba38fbf4b30b9b4ee65f1966f08",
      "5fae06f0a06f4249af7953a25fa3e344",
      "9626370839184d05ac9d57a4ae6acaa6",
      "f69fd56bd1ca4b32be0c876b429025f4",
      "01cb643764dc48c6ae3cb555586d0612",
      "d93f590c0785442b8cbae277d1d7a127"
     ]
    },
    "id": "fBbTZqmrL7Pz",
    "outputId": "296a5869-e057-4b79-b244-e68fc41c79be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code start: Dataset and DataLoader preparation...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/321 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders prepared successfully.\n",
      "Code finished in 1.26 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Code start: Dataset and DataLoader preparation...\")\n",
    "\n",
    "# Define dataset class\n",
    "class MHTextDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.texts = df['statement'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mental/mental-bert-base-uncased\")\n",
    "\n",
    "# Create datasets\n",
    "train_ds = MHTextDataset(train_df, tokenizer)\n",
    "val_ds = MHTextDataset(val_df, tokenizer)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"DataLoaders prepared successfully.\")\n",
    "print(\"Code finished in\", round(end_time - start_time, 2), \"seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8im20tXMMz4"
   },
   "source": [
    "## 6. Model, Optimizer & Scheduler\n",
    "Description:\n",
    "Loads the MentalBERT pretrained model with a classification head for 4 classes. Sets up AdamW optimizer with weight decay and a linear learning rate scheduler with warmup. Class weights are applied in the loss function to address imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205,
     "referenced_widgets": [
      "6d4035a94a044ffa9976860d79f4975c",
      "3fd85eb60c1e4b7f814a70175c1cfc6f",
      "428ebc02c9714fc19d6f5fe5e30fb748",
      "b0c408f016f54e709202bd333cb42e2c",
      "8d1ac622872c4c58b8148ba0c2699cb0",
      "606c95a13e9e4c6cba106791f2910152",
      "846fe644c20a4a11a02a14da2e441e94",
      "c4058ca4434d4ee9b0b8e51211ab953e",
      "78944a9748c54f2d8b7cd449c50298a7",
      "d9d9ee3e24214848980d03b339c2d3be",
      "f669fd0ec6864d43957e1061bb718598",
      "efc3ee58108c4d92b59b3945b2bb5454",
      "55ef176d463f4275a33ab272bf1737cc",
      "872887b189dc400694b85bea04625bc4",
      "bf59f907399d4834a8a99cf2d583df1b",
      "97280f1a7b174c4ab158207a63da4e56",
      "eded04edf5a147db86c886afbcc9e290",
      "981c3e1f3ac141efb5f3ba1673241ae7",
      "a72d1bdfe9814abebd513910b4b55810",
      "57c3b17d3e7446e9812b5bc431b8bd54",
      "4f3559cfe71d4f3f829383a3935205a6",
      "084139387dd54ecaae04be548769dde7"
     ]
    },
    "id": "Bog9vjQ5MyHF",
    "outputId": "d54a0af2-6839-470a-8134-7d1a0efa10b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code start: Model initialization and optimizer setup...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/639 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at mental/mental-bert-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([8.0567e-05, 1.0325e-04, 7.8168e-05, 1.4186e-04], device='cuda:0')\n",
      "Model, optimizer, and scheduler initialized.\n",
      "Code finished in 7.49 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\"Code start: Model initialization and optimizer setup...\")\n",
    "\n",
    "# Initialize model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"mental/mental-bert-base-uncased\",\n",
    "    num_labels=4  # Focusing on Anxiety, Depression, Normal, Suicidal\n",
    ").to(device)\n",
    "\n",
    "# Compute class weights for imbalanced dataset\n",
    "class_counts = train_df['label'].value_counts().sort_index().values\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5, weight_decay=1e-2)\n",
    "\n",
    "# Learning rate scheduler\n",
    "epochs = 5\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=total_steps // 10,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Model, optimizer, and scheduler initialized.\")\n",
    "print(\"Code finished in\", round(end_time - start_time, 2), \"seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-yjRzHnM23t"
   },
   "source": [
    "## 7. Training Loop\n",
    "Runs multiple epochs of training with gradient clipping and loss backpropagation. After each epoch, evaluates on validation data and saves the best model based on macro F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpBzG3HBM4qz",
    "outputId": "5cc02e3e-9133-48ec-fe40-91ae735894f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code start: Training loop...\n",
      "Epoch 1 | Average Train Loss: 0.2551\n",
      "Epoch 1 | time taken: 894.86 seconds\n",
      "Epoch 2 | Average Train Loss: 0.1729\n",
      "Epoch 2 | time taken: 1789.67 seconds\n",
      "Epoch 3 | Average Train Loss: 0.0986\n",
      "Epoch 3 | time taken: 2684.23 seconds\n",
      "Epoch 4 | Average Train Loss: 0.0527\n",
      "Epoch 4 | time taken: 3578.5 seconds\n",
      "Epoch 5 | Average Train Loss: 0.0299\n",
      "Epoch 5 | time taken: 4472.9 seconds\n",
      "Training completed.\n",
      "Total training time: 4472.9 seconds.\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "best_val_f1 = 0.0\n",
    "\n",
    "print(\"Code start: Training loop...\")\n",
    "train_start = time.time()\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Move batch to device\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Compute weighted loss\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fn(logits, inputs['labels'])\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        # Optimizer & scheduler step\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch} | Average Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Epoch {epoch} | time taken: {round(time.time() - train_start, 2)} seconds\")\n",
    "\n",
    "train_end = time.time()\n",
    "print(\"Training completed.\")\n",
    "print(\"Total training time:\", round(train_end - train_start, 2), \"seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPfxS7DXO8XP"
   },
   "source": [
    "*Decision Note: Gradient clipping prevents exploding gradients common in transformers. Early stopping based on validation F1 ensures the model generalizes well without overfitting. Saving the best model checkpoint enables rollback and deployment readiness.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rT7TXojJwZ2F"
   },
   "source": [
    "**Inference:** *The steady decrease in training loss from 0.2551 to 0.0299 over 5 epochs indicates effective model learning and convergence.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysKS9uGhNf_i"
   },
   "source": [
    "## 8. Validation\n",
    "Evaluates the saved best model on the validation set, generating detailed classification reports and confusion matrices for performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tAgWEX7NqiO",
    "outputId": "0ef848f1-2492-4f5d-dfa1-bd3a34fd4c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.0299 | Val Macro F1: 0.8782\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        # Move batch to device\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs).logits\n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(inputs['labels'].cpu().numpy())\n",
    "\n",
    "# Compute metrics\n",
    "report = classification_report(\n",
    "    all_labels, all_preds,\n",
    "    target_names=[id2label[i] for i in range(4)],\n",
    "    output_dict=True\n",
    ")\n",
    "val_f1 = report['macro avg']['f1-score']\n",
    "\n",
    "print(f\"Epoch {epoch} | Train Loss: {avg_train_loss:.4f} | Val Macro F1: {val_f1:.4f}\")\n",
    "\n",
    "# Save best model checkpoint\n",
    "if val_f1 > best_val_f1:\n",
    "    best_val_f1 = val_f1\n",
    "    torch.save(model.state_dict(), 'best_phase2.pth')\n",
    "    print(\"  --> New best model checkpoint saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3mIOdeNws6o"
   },
   "source": [
    "**Inference:**\n",
    "* The validation macro F1 gradually improved, peaking at ~0.878, reflecting\n",
    "balanced performance across all target classes.\n",
    "* Real-time evaluation enabled checkpoint saving based on best F1, ensuring the best model state is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpywIWeWwPDE"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_phase2.pth')\n",
    "\n",
    "files.download('model_phase2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "666oLtogNqHb"
   },
   "source": [
    "## 9. Final Evaluation\n",
    "Reports total runtime and marks notebook completion for reproducibility and performance tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "p0zZ_ad7NstB",
    "outputId": "3455bdb2-70f8-4205-f93a-1d3139466cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxiety       0.99      1.00      0.99      3103\n",
      "  Depression       0.82      0.77      0.79      2421\n",
      "      Normal       0.98      0.98      0.98      3198\n",
      "    Suicidal       0.72      0.77      0.74      1763\n",
      "\n",
      "    accuracy                           0.90     10485\n",
      "   macro avg       0.88      0.88      0.88     10485\n",
      "weighted avg       0.90      0.90      0.90     10485\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the best model checkpoint\n",
    "model.load_state_dict(torch.load('best_phase2.pt', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Compute predictions on the validation set\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "        logits = model(**inputs).logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(inputs['labels'].cpu().numpy())\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nValidation Classification Report:\\n\")\n",
    "print(classification_report(\n",
    "    all_labels, all_preds,\n",
    "    target_names=[id2label[i] for i in range(4)]\n",
    "))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d',\n",
    "            xticklabels=[id2label[i] for i in range(4)],\n",
    "            yticklabels=[id2label[i] for i in range(4)],\n",
    "            cmap='Blues')\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.title(\"Validation Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLWdZBwfxIM7"
   },
   "source": [
    "## Inference\n",
    "\n",
    "- **Anxiety & Normal:** Nearly perfect metrics; the model identifies these classes with excellent reliability.\n",
    "- **Depression & Suicidal:** Moderate scores; most misclassifications occur between these classes due to semantic overlap.\n",
    "- **Overall:** 90% accuracy and 0.88 macro F1 reflect strong generalization.\n",
    "- **Confusion Matrix:** Errors are mainly between Depression and Suicidal; other classes are rarely confused.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBRtxvxKx518"
   },
   "source": [
    "## 10. Next Step: Model Testing\n",
    "\n",
    "- Evaluate the trained model on a held-out test set to assess real-world performance.\n",
    "- Report test set accuracy, precision, recall, F1-score, and confusion matrix.\n",
    "- Use these metrics to guide further refinements and to validate model generalization before deployment.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
