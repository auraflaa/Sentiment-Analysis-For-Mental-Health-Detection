{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4c71af-563c-4487-b935-6b3de73fdfb5",
   "metadata": {},
   "source": [
    "# Mental Health Dataset Creation\r\n",
    "\r\n",
    "This notebook creates a new, balanced mental health testing dataset and an updated training dataset to be used in Phase 3. The aim is to supplement the previous data with more diverse sources, combining clinical and social media content for improved model robustness and generalization. The resulting datasets will provide a stronger foundation for evaluating and retraining your classifier in the next modeling phase.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1444ef-dad2-4ea3-b80d-d093f3ca800b",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b3ea4a3b-5917-47a1-a0cd-b6ab41a1d193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441b040-6ab4-49cd-af80-d3af04dd47bb",
   "metadata": {},
   "source": [
    "## 2. Load your datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3def8fe7-bd80-4010-8ecd-3bc9af1c4649",
   "metadata": {},
   "outputs": [],
   "source": [
    "suicide_df = pd.read_csv(\"Suicide_Detection.csv\")     \n",
    "posts_train = pd.read_csv(\"posts_train.csv\")       \n",
    "posts_test = pd.read_csv(\"posts_test.csv\")           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399f4e83-9311-41dc-9f3d-5980e10cefdb",
   "metadata": {},
   "source": [
    "## 3. Inspect Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4a4815dd-a99b-42d3-9226-30c3b69a2d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully.\n",
      "Suicide_Detection: (232074, 3)\n",
      "posts_train: (13727, 4)\n",
      "posts_test: (1488, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Datasets loaded successfully.\")\n",
    "print(\"Suicide_Detection:\", suicide_df.shape)\n",
    "print(\"posts_train:\", posts_train.shape)\n",
    "print(\"posts_test:\", posts_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb370c94-4331-4add-bbf1-58559f60839a",
   "metadata": {},
   "source": [
    "## 3. Normalize column names\n",
    "Renames disparate columns (e.g., 'post', 'classname', 'class') so all DataFrames share the same names ('text' for statements/posts, 'status' for class labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "403f6971-17b6-4e26-a636-4195c23ca138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Suicide Detection: use 'text' and 'class'\n",
    "suicide_df = suicide_df[['text', 'class']].rename(columns={'class':'status'})\n",
    "\n",
    "# For Posts: use 'post' and 'class_name'\n",
    "posts_train = posts_train[['post', 'class_name']].rename(columns={'post': 'text', 'class_name': 'status'})\n",
    "posts_test = posts_test[['post', 'class_name']].rename(columns={'post': 'text', 'class_name': 'status'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ee0513-5a67-42ee-b191-1841d34dd7ae",
   "metadata": {},
   "source": [
    "## 5. Combine datasets\n",
    "Concatenates suicidedf and poststest into a single DataFrame (combineddf) for creating a unified test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "64565746-bbe9-4a16-8f60-ef0254a7a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([suicide_df, posts_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe544b-d7eb-47b5-9807-30d66c15f6e6",
   "metadata": {},
   "source": [
    "## 4. Normalize labels to four classes\n",
    "Maps string labels in test data to integers (consistent with training), handles potential label typos by dropping unmapped samples, and prints new label distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "f318ae5c-0bed-4aac-ad33-517841e666c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_label(label):\n",
    "    label = str(label).strip().title()\n",
    "    mapping = {\n",
    "        'Suicide': 'Suicidal',\n",
    "        'Suicidal': 'Suicidal',\n",
    "        'Non-Suicide': 'Normal',\n",
    "        'Normal': 'Normal',\n",
    "        'Depression': 'Depression',\n",
    "        'Depressed': 'Depression',\n",
    "        'Anxiety': 'Anxiety',\n",
    "    }\n",
    "    return mapping.get(label, label)\n",
    "\n",
    "combined_df['status'] = combined_df['status'].apply(normalize_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e39dd68-d1a7-4fcb-bcb0-29e7d2290407",
   "metadata": {},
   "source": [
    "*Decision Note: Label normalization ensures all downstream analysis and modeling work consistently, despite differences in original labeling. It prevents confusion and invalid mappings.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12679eb-1419-4537-ad0b-4b63ac438c4c",
   "metadata": {},
   "source": [
    "## 5. Fltering Required Classes\n",
    "Filters dataset to only include rows with the four desired classes; prints the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5818d0ee-3f58-40a2-ac1e-0394332bcbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before balancing:\n",
      "status\n",
      "Suicidal      116037\n",
      "Normal        116037\n",
      "Depression       248\n",
      "Anxiety          248\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_classes = ['Suicidal', 'Depression', 'Anxiety', 'Normal']\n",
    "filtered_df = combined_df[combined_df['status'].isin(target_classes)].copy()\n",
    "\n",
    "print(\"Class distribution before balancing:\")\n",
    "print(filtered_df['status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f55562-5bce-4e9e-b287-a4cb9d84b163",
   "metadata": {},
   "source": [
    "## 6. Remove duplicates and missing\n",
    "Drops rows with missing 'text' or 'status' values and removes duplicate text entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "54867528-b610-4560-ac12-549a817dedf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.dropna(subset=['text', 'status'])\n",
    "filtered_df = filtered_df.drop_duplicates(subset=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f440d2-264d-48a5-af00-1dbdcd52b71f",
   "metadata": {},
   "source": [
    "## 7. Check results\n",
    "Displays value counts and sample rows from the cleaned, filtered DataFrame for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "07eab4d1-43c8-4621-a1e0-6bc2695bb0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "Suicidal      116037\n",
      "Normal        116037\n",
      "Depression       248\n",
      "Anxiety          248\n",
      "Name: count, dtype: int64\n",
      "                                                text    status\n",
      "0  Ex Wife Threatening SuicideRecently I left my ...  Suicidal\n",
      "1  Am I weird I don't get affected by compliments...    Normal\n",
      "2  Finally 2020 is almost over... So I can never ...    Normal\n",
      "3          i need helpjust help me im crying so hard  Suicidal\n",
      "4  I’m so lostHello, my name is Adam (16) and I’v...  Suicidal\n"
     ]
    }
   ],
   "source": [
    "print(filtered_df['status'].value_counts())\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c68d0-8314-47ac-a0cd-6001dfecbe2d",
   "metadata": {},
   "source": [
    "## 8. Class Balancing\n",
    "Downsamples every class to the size of the minority class so all are equally represented (248 per class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c41be9d7-2656-4f8f-a6ca-f05ef4bc4938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "Anxiety       248\n",
      "Depression    248\n",
      "Normal        248\n",
      "Suicidal      248\n",
      "Name: count, dtype: int64\n",
      "                                                text   status\n",
      "0  i don't understand whats wrong with me. i don'...  Anxiety\n",
      "1  usually when i have anxiety just chatting with...  Anxiety\n",
      "2  well, i've had anxiety and panic syndrome for ...  Anxiety\n",
      "3  for the most minimal of things, like standing ...  Anxiety\n",
      "4  i stay away from family and live with my roomm...  Anxiety\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\AppData\\Local\\Temp\\ipykernel_29588\\2032894425.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: x.sample(n=desired_n, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "desired_n = 248  # Match the minority class count\n",
    "\n",
    "balanced_df = (\n",
    "    filtered_df.groupby('status', group_keys=False)\n",
    "    .apply(lambda x: x.sample(n=desired_n, random_state=42))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(balanced_df['status'].value_counts())\n",
    "print(balanced_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc66db4f-7d9b-4448-ad56-8cb6f27a8cb0",
   "metadata": {},
   "source": [
    "## Save combined dataset for model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2ec70c47-0d72-4bed-bbe4-d5420430fedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined test dataset saved as 'mental_health_combined_test.csv'\n"
     ]
    }
   ],
   "source": [
    "balanced_df.to_csv(\"mental_health_combined_test.csv\", index=False, encoding='utf-8')\n",
    "print(\"Combined test dataset saved as 'mental_health_combined_test.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11af5163-d816-4b27-b4b0-c86b4c6c38e4",
   "metadata": {},
   "source": [
    "## Save combined dataset for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "88f1f4a9-2fd4-4002-af16-4761eb0c1fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced training data saved as 'mental_health_balanced_train.csv'\n"
     ]
    }
   ],
   "source": [
    "combined_train = pd.concat([posts_train, suicide_df], ignore_index=True)\n",
    "combined_train['status'] = combined_train['status'].apply(normalize_label)\n",
    "target_classes = ['Suicidal', 'Normal', 'Depression', 'Anxiety']\n",
    "sample_size = min(\n",
    "    combined_train['status'].value_counts()[['Depression', 'Anxiety']].min(),  # smallest minority class\n",
    "    2400  # cap at 2400 for practical balance if needed\n",
    ")\n",
    "\n",
    "# Sample equally from each class\n",
    "balanced_samples = []\n",
    "for cls in target_classes:\n",
    "    cls_subset = combined_train[combined_train['status'] == cls]\n",
    "    # If class has enough samples, randomly sample without replacement; else, use all available\n",
    "    balanced_cls = cls_subset.sample(n=sample_size, random_state=42) if len(cls_subset) >= sample_size else cls_subset\n",
    "    balanced_samples.append(balanced_cls)\n",
    "\n",
    "balanced_train = pd.concat(balanced_samples, ignore_index=True)\n",
    "\n",
    "# Shuffle the balanced dataframe\n",
    "balanced_train = balanced_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save to CSV\n",
    "balanced_train.to_csv(\"mental_health_balanced_train.csv\", index=False, encoding='utf-8')\n",
    "print(\"Balanced training data saved as 'mental_health_balanced_train.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
